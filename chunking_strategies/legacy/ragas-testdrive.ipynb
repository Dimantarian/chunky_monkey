{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/datasets/load.py:1461: FutureWarning: The repository for explodinggradients/amnesty_qa contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/explodinggradients/amnesty_qa\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/huggingface_hub/repocard.py:105: UserWarning: Repo card metadata block was not found. Setting CardData to empty.\n",
      "  warnings.warn(\"Repo card metadata block was not found. Setting CardData to empty.\")\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "from datasets import load_dataset\n",
    "\n",
    "amnesty_qa = load_dataset(\"explodinggradients/amnesty_qa\", \"english_v2\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'ground_truth', 'answer', 'contexts'],\n",
       "    num_rows: 20\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amnesty_qa['eval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    ")\n",
    "from ragas.metrics.critique import harmfulness\n",
    "\n",
    "# list of metrics we're going to use\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    harmfulness,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "azure_configs = {\n",
    "    \"base_url\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"model_deployment\": os.getenv(\"GEN_STEP_MODEL\"),\n",
    "    \"model_name\": os.getenv(\"GEN_STEP_MODEL\"),\n",
    "    \"embedding_deployment\": os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\"),\n",
    "    \"embedding_name\": os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\"),  # most likely\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import AzureChatOpenAI\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "from ragas import evaluate\n",
    "\n",
    "azure_model = AzureChatOpenAI(\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    azure_endpoint=azure_configs[\"base_url\"],\n",
    "    azure_deployment=azure_configs[\"model_deployment\"],\n",
    "    model=azure_configs[\"model_name\"],\n",
    "    validate_base_url=False,\n",
    ")\n",
    "\n",
    "# init the embeddings for answer_relevancy, answer_correctness and answer_similarity\n",
    "azure_embeddings = AzureOpenAIEmbeddings(\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    azure_endpoint=azure_configs[\"base_url\"],\n",
    "    azure_deployment=azure_configs[\"embedding_deployment\"],\n",
    "    model=azure_configs[\"embedding_name\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2189dfd46f9747229676fddd9c6ffb6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/ragas/executor.py\", line 79, in _aresults\n",
      "    r = await future\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/asyncio/tasks.py\", line 615, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "           ^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/ragas/executor.py\", line 38, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/ragas/executor.py\", line 112, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/ragas/metrics/base.py\", line 116, in ascore\n",
      "    raise e\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/ragas/metrics/base.py\", line 112, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/ragas/metrics/_faithfulness.py\", line 204, in _ascore\n",
      "    answer_result = await self.llm.generate(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/ragas/llms/base.py\", line 110, in generate\n",
      "    return await loop.run_in_executor(None, generate_text)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/tenacity/__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/tenacity/__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/tenacity/__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/tenacity/__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/ragas/llms/base.py\", line 139, in generate_text\n",
      "    return self.langchain_llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
      "    raise e\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 548, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 581, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/openai/_base_client.py\", line 1232, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/openai/_base_client.py\", line 1012, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/ragas/executor.py\", line 79, in _aresults\n",
      "    r = await future\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/asyncio/tasks.py\", line 615, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "           ^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/ragas/executor.py\", line 38, in sema_coro\n",
      "    return await coro\n",
      "           ^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/ragas/executor.py\", line 112, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/ragas/metrics/base.py\", line 116, in ascore\n",
      "    raise e\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/ragas/metrics/base.py\", line 112, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/ragas/metrics/critique.py\", line 128, in _ascore\n",
      "    result = await self.llm.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/ragas/llms/base.py\", line 110, in generate\n",
      "    return await loop.run_in_executor(None, generate_text)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/tenacity/__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/tenacity/__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/tenacity/__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/tenacity/__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/ragas/llms/base.py\", line 139, in generate_text\n",
      "    return self.langchain_llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
      "    raise e\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 548, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 277, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 581, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/openai/_base_client.py\", line 1232, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/openai/_base_client.py\", line 921, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/guy/miniconda3/envs/bert/lib/python3.11/site-packages/openai/_base_client.py\", line 1012, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.8904, 'answer_relevancy': 0.0526, 'context_recall': 0.9218, 'context_precision': 0.9748, 'harmfulness': 0.8487}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = evaluate(\n",
    "    amnesty_qa[\"eval\"], metrics=metrics, llm=azure_model, embeddings=azure_embeddings, raise_exceptions=False\n",
    ")\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>harmfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the global implications of the USA Su...</td>\n",
       "      <td>The global implications of the USA Supreme Cou...</td>\n",
       "      <td>The global implications of the USA Supreme Cou...</td>\n",
       "      <td>[- In 2022, the USA Supreme Court handed down ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988043</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which companies are the main contributors to G...</td>\n",
       "      <td>According to the Carbon Majors database, the m...</td>\n",
       "      <td>According to the Carbon Majors database, the m...</td>\n",
       "      <td>[In recent years, there has been increasing pr...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956722</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which private companies in the Americas are th...</td>\n",
       "      <td>The largest private companies in the Americas ...</td>\n",
       "      <td>According to the Carbon Majors database, the l...</td>\n",
       "      <td>[The issue of greenhouse gas emissions has bec...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.988319</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What action did Amnesty International urge its...</td>\n",
       "      <td>Amnesty International urged its supporters to ...</td>\n",
       "      <td>Amnesty International urged its supporters to ...</td>\n",
       "      <td>[In the case of the Ogoni 9, Amnesty Internati...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.933254</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the recommendations made by Amnesty I...</td>\n",
       "      <td>The recommendations made by Amnesty Internatio...</td>\n",
       "      <td>Amnesty International made several recommendat...</td>\n",
       "      <td>[In recent years, Amnesty International has fo...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993686</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What are the global implications of the USA Su...   \n",
       "1  Which companies are the main contributors to G...   \n",
       "2  Which private companies in the Americas are th...   \n",
       "3  What action did Amnesty International urge its...   \n",
       "4  What are the recommendations made by Amnesty I...   \n",
       "\n",
       "                                        ground_truth  \\\n",
       "0  The global implications of the USA Supreme Cou...   \n",
       "1  According to the Carbon Majors database, the m...   \n",
       "2  The largest private companies in the Americas ...   \n",
       "3  Amnesty International urged its supporters to ...   \n",
       "4  The recommendations made by Amnesty Internatio...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The global implications of the USA Supreme Cou...   \n",
       "1  According to the Carbon Majors database, the m...   \n",
       "2  According to the Carbon Majors database, the l...   \n",
       "3  Amnesty International urged its supporters to ...   \n",
       "4  Amnesty International made several recommendat...   \n",
       "\n",
       "                                            contexts  faithfulness  \\\n",
       "0  [- In 2022, the USA Supreme Court handed down ...           NaN   \n",
       "1  [In recent years, there has been increasing pr...      1.000000   \n",
       "2  [The issue of greenhouse gas emissions has bec...      1.000000   \n",
       "3  [In the case of the Ogoni 9, Amnesty Internati...      0.833333   \n",
       "4  [In recent years, Amnesty International has fo...      1.000000   \n",
       "\n",
       "   answer_relevancy  context_recall  context_precision  harmfulness  \n",
       "0               NaN             1.0           0.988043          1.0  \n",
       "1               0.0             1.0           0.956722          1.0  \n",
       "2               0.0             0.3           0.988319          1.0  \n",
       "3               0.0             0.8           0.933254          1.0  \n",
       "4               0.0             1.0           0.993686          1.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = result.to_pandas()\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
