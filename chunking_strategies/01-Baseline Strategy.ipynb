{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00- Baseline Strategy\n",
    "\n",
    "## RAGE-1: RAG Experiment Harness\n",
    "\n",
    "### Setting up the Experiment\n",
    "\n",
    "Having ran [00-Chunking Strategies](./00-Chunking%20Strategies.ipynb) we now have our base data and our evaluation dataset. Now it's time to run our first experiment!\n",
    "\n",
    "Given a dataframe containing our chunked documents we must:\n",
    "\n",
    "- Chunk the documents\n",
    "- Embed the chunks.\n",
    "- Store it in a vector database.\n",
    "- Query the db using our ground truth (GT) question answer pairs.\n",
    "- Create a generation prompt which includes the question, and the retrieved \"context\".\n",
    "- Run the generation prompt and store the Question, Answer, GT Answer, Context for our evaluation framework.\n",
    "\n",
    "Let's follow our [baseline experiment](experiments/01-chunking-strategies-baseline.md). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "experiment_name = \"baseline_pubmed_articles\"\n",
    "evaluation_data = pd.read_csv('data/qa_pairs.csv')\n",
    "input_data = pd.read_csv('data/ds_subset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunking the documents\n",
    "\n",
    "Based on our earlier analysis, let's take a chunk size of 400 words with an overlap of 50. We can calculate the exact length of requests later, but 400 words is approximately 500 tokens per chunk based on our analysis and we should be able to fit multiple results into our context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag.chunking import chunk_string_with_overlap\n",
    "\n",
    "# Create a new DataFrame with each chunk as a separate row\n",
    "chunks = []\n",
    "doc_ids = []\n",
    "chunk_ids = []\n",
    "for idx, row in input_data.iterrows():\n",
    "    article_chunks = chunk_string_with_overlap(input_text=row['article'], chunk_length=400, overlap=50)\n",
    "    chunks.extend(article_chunks)\n",
    "    doc_ids.extend([row['doc_id']] * len(article_chunks))\n",
    "    chunk_ids.extend([f\"{row['doc_id']}-{i+1}\" for i in range(len(article_chunks))])\n",
    "\n",
    "ds_chunked = pd.DataFrame({'doc_id': doc_ids, 'chunk_id': chunk_ids, 'chunks': chunks})\n",
    "ds_chunked.to_csv('data/ds_chunked.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some of our chunks - it helps to do a sense check as if we see something wrong, it's a lot easier to fix now than after creating your embeddings and search indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutoff values for stg and stg / tsh ratio in our study have high sensitivity and specificity in predicting the outcome . this study is one of its kinds , investigating the association of stg / tsh ratio with ablation outcome in patients with dtc . we found that patients with stg / tsh ratio < 0.35 before rra had 11.64 times greater chance of successful ablation compared to those with stg / tsh ratio > 0.35 with sensitivity of 80.0% and specificity of 81.4% ( p . however limitation of our study was its retrospective nature ; therefore , we could retrieve data of only 75 patients who fulfilled our inclusion criteria . many of the previous studies regarding role of stg in predicting rra outcome were also retrospective in nature [ 8 , 15 , 16 , 18 , 29 , 31 ] . another limitation of this study is use of different ablative doses in low , intermediate , and high risk groups which could have an impact on success of ablation as british thyroid association 2007 guidelines favor use of high dose for rra . our data do not show a significant impact of dose of rra upon outcome and this is in concordance with two recently published prospective trials claiming no difference in outcomes in patients treated with 30 and 100 mci rra ( 32,33 ) . because of its smaller sample size , the result of this study should be interpreted cautiously and we recommend further studies not only to validate the cutoff levels that we have set but also to confirm the other findings of this study . our study adds to the value of preablation stg and establishes the role of preablation stg / tsh ratio in predicting the ablation outcome . one of the suggestions that came out from this study is that preablation stg / tsh ratio might be used for risk stratification , as till now there is no laboratory parameter in the risk stratification of the ata and eta for dtc before ablation . so patients with stg / tsh ratio > 0.35 can be placed in ata and eta high risk categories as stg / tsh ratio has even more significant association with rra outcome than size and capsular invasion . however considering the limited sample size in this study , further studies are warranted to confirm\n",
      "\n",
      "\n",
      "networks isolates are not depicted ) . on the periphery of both posttest networks one can see that many participants only have one or two intransitive ties , contributing to decreased constraint . yet , at the same time , one can see an increased number of triangles in the posttest networks in comparison to the pretest network , indicating the tendency toward transitive closure . the results suggest a tendency for parents to form new friendship ties with other parents whose child 's bmi z - score is similar to their own child 's bmi z - score , ( t = 2.08 , p < .05 ; table 5 ) . there was no significant selection effect for maternal bmi in the formation of new social ties ; that is , overweight mothers were not more likely to select overweight mothers as friends ( p > .05 ) . several research teams have empirically linked social network structures to adult and adolescent obesity [ 13 , 15 , 21 ] . to date , very little research elucidates the network context of obesity among children . while many obesity interventions occur in a group setting , underlying group structure and group processes are not documented in the scientific literature . our research demonstrates that a new social network evolved among families participating in a pediatric obesity group - based prevention trial . moreover , these new social ties formed in a predictable manner , with mothers forming friendship ties with other mothers ' who had children of similar body type . social norms are thought to at least partially account for the clustering of health behaviors among social contacts [ 12 , 13 , 44 ] . their findings suggest that social norms specific to one 's social network ( subjective norms ) influence weight more than broad societal level social norms ( injunctive norms ) . subsequently , social network phenomena might explain some of the factors that underlie the misperception of body size and the social context in which they develop and are maintained . parental misperceptions of child weight status are well documented , even among parents of preschool aged children [ 46 , 47 ] , and affect the likelihood that parents will take action to ameliorate their child 's weight problem . we did not find overweight mothers to be more likely to\n",
      "\n",
      "\n",
      "nmda receptor encephalitis , the iq test showed no significant change except for performance iq improvement from 58 to 64 . she still had residual sequelae of mild mental retardation , and she had a mildly impulsive personality and was easily distracted . the typical presentations of anti - nmda receptor encephalitis could be divided into eight categories in decreasing order of prevalence , including acute behavioral or cognitive change , movement disorder , memory deficit , speech disorder , seizure , decreased level of consciousness , autonomic dysfunction , and central hypoventilation . in an observational cohort study , about 87% of patients shared similar symptoms that included four or more of the eight categories within the first 4 weeks.3 definite diagnosis for this disease was the presence of nmda receptor antibodies in the patient s cerebrospinal fluid ( 100% sensitivity ) or serum ( 85% sensitivity).2,3 reduced levels of cerebrospinal fluid antibodies appeared to be correlated to a better clinical outcome.2,8 there were no correlations between different domains of symptoms , extent of disease progression , and brain mri findings , with only 33%50% of patients showing nonspecific abnormalities on standard mri.2,3 one recent functional mri study proposed that reduced functional connectivity between bilateral hippocampus may predict memory performance , and that extensive white - matter changes in diffusion tensor imaging might correlate to the disease severity.9 the acronym nmdar is useful as a mnemonic for remembering the symptoms of anti - nmda receptor encephalitis : n for nonspecific prodrome , r for respiration depression . early detection of this disease and confirmed diagnosis with nmda receptor antibodies ensures early intervention and better recovery . the recommended first - line immunotherapies were corticosteroid , intravenous immunoglobulin , and plasmaphoresis . about 60% of patients achieved good outcomes with minor functional deficits remaining after first - line therapy or tumor removal.3 the second - line immunotherapies , which include rituximab and cyclophosphamide , were recommended to be started if patients failed to respond to first - line therapies after no more than 4 weeks,2,3 and resulted in a response rate of approximately 78%.3 full recovery and fewer neurological relapses were more frequently seen in patients with teratoma that had been removed.2,3,10 the general relapsing rate was 12%24% within the first 2 years , and overall mortality rate was 4%9.5%.2,3 a search of relevant articles was conducted on pubmed (\n",
      "\n",
      "\n",
      "comment on possible structural implications of these observations . in this paper , we present a complete rewrite of mavl / stickwrld in java3d ( ) . the new implementation has three significant areas of improvement over the vrml version : enhanced real - time user interaction ; clustering of residues by aggregate physicochemical properties and availability of pre - calculated stickwrld wrlds for all families in the pfam database ( 3 ) . our java3d implementation leaves the computationally intensive calculation of the complete interpositional correlation matrix on the server , but moves the selection of features for display , to the client applet running on the user 's computer . it is no - longer necessary to completely re - compute the correlation matrix to change display preferences . therefore the user interface is no longer limited to a static graph with pre - applied statistical and display parameter choices . instead , the various stickwrld statistical parameters ( tr , the global over / underpopulation threshold ; pr , the per - edge overpopulation threshold ; nr , the per - edge underpopulation threshold ; and alpha , the edge - significance threshold ) , and display parameters such as residue coloring and grouping can be adjusted by the user on - the - fly . this allows the parameters to be adjusted to suit the complexity of the alignment being visualized , and the user can now toggle between coarse visualization parameters to quickly explore and locate interesting features of an alignment , and fine parameters to investigate detailed aspects of the relationship . to allow the system to more intuitively deal with the potentially weak relationships amongst poorly constrained sequences , this allows , for example , the conserved residue properties and interpositional requirements of distant homologs to be discovered , even in the absence of specifically conserved residues . residues can currently be grouped by hydropathy , charge and volume , and the relationship between these aggregate properties at each position visualized , just as the specific sequence identities can be . using this option in many protein families results in the discovery of correlated physical properties , even when the contributing residue identities fall below the significance threshold , or are obscured by other more dramatic individual - residue relationships . finally , we are interested in the distribution of the variety of\n",
      "\n",
      "\n",
      "allergic episode , leads to maintaining lower affinity antibodies . this would be an explanation to the fact that patients sensitized to anisakis do not react with acute type 1 hypersensitivity reactions in provocation tests with non viable anisakis larvae [ 28 , 29 ] . furthermore , blocking antibodies , such as igg4 included in the igg compartment , with confirmed higher avidities in gaa could , by competing with the same epitopes recognized by ige , prevent mast cell activation and the subsequent allergic episode , when anisakis contaminated fish ( nonviable or inactivated larvae ) is well tolerated by patients with previous gaa . interestingly , if we look at the diverging correlation of avigg and avige with specific ige , we can also postulate that avidity is not only the outcome of an affinity maturation process of antibodies within an antibody isotype , but also the outcome of a mechanism , in which probably outcompeting of an immunoglobulin isotype over another could have been resulted by high - affinity antibodies in the maturation process . a possible drawback of these results is of methodological concern , as there could be some controversy about the influence of igg antibodies on an elisa assay in avidity studies . however , previous studies with using thiocyanate as denaturing agent showed independence of immunoglobulin levels and avidity and lack of independence between avidity indexes and immunoglobulin concentrations [ 26 , 31 ] . therefore , our finding of a negative correlation of specific ige with avidity is not expected to be influenced by a methodological constraint . we did not show a direct negative correlation between avige and avigg , but this could be due to the fact that we did not measure differential epitope affinity and the high variation of binding capacities and maturation process of antibodies between individuals . in this respect it is interesting to note that differences in the generation of high - affinity ige antibodies could be due to differences in sequential class switching versus direct class switching from igm , although animal models and application in human allergic disease are still a matter of debate [ 14 , 27 ] . the specific affinity maturation in anisakis - associated allergic disease has not been studied so far , but our results could lead to a testable hypothesis , where clinically different cu+ and gaa\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display a random sample of the chunked data show the full string\n",
    "for chunk in ds_chunked['chunks'].sample(5):\n",
    "    print(chunk)\n",
    "    print('\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already we can see that sentences are broken, and that perhaps this isn't a great way of splitting our information. That being said we are generating a baseline and we expect the subsequent experiments to offer significant uplift. For now let's proceed.\n",
    "\n",
    "> KEY TAKEAWAY: Even before we've run expensive and time consuming API calls, we can see that the results are not ideal. It's often worth iterating on this before investing time and money in the more nuanced tuning approaches.\n",
    "\n",
    "#### Embed the chunks\n",
    "\n",
    "We will use the `ada-v2` embedding model for this example as it is fairly powerful and well understood. It's worth noting that this will not always be the best model, paticularly when data contains topics and content that relate to finding outside of the embedding model's training data. Fine tuning an embedding model on a specific corpus (particularly in the case of highly specialised data) is also a popular option.\n",
    "\n",
    "Most vector databases implement a wrapper around common embedding functions. Here we will configure and use the wrapper for openai embeddings in ChromaDB. This function is used to embed all documents in a collection, and also to embed queries as they come in.\n",
    "\n",
    "In creating the index, we also need to specify the measurement method. For illustratice purposes we've used cosine similarity. In reality, for enterprise use cases index design is a rich topic in itself. Again, call out if you'd like more content on index design and choice of search engine! \n",
    "\n",
    "> KEY TAKEAWAY: Your choice of embedding model matters! It should be consistent across your index. and should be relevant to your data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(find_dotenv())   \n",
    "# Specify Embedding model\n",
    "embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")\n",
    "\n",
    "# Used in chromadb to embed docs and queries\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "                api_base=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "                api_type=\"azure\",\n",
    "                api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "                model_name=embedding_model\n",
    "            )\n",
    "# Create a new collection in ChromaDB\n",
    "\n",
    "from chromadb import PersistentClient\n",
    "\n",
    "chroma_client = PersistentClient(path=\"./data/chroma_db\")\n",
    "\n",
    "index_name = f\"experiment_{experiment_name}\"\n",
    "collection = chroma_client.get_or_create_collection(name=index_name,embedding_function=openai_ef, metadata={\"hnsw:space\": \"cosine\"})\n",
    "\n",
    "collection.add(\n",
    "    # embeddings=ds_chunked['ada_v2'].tolist(),\n",
    "    documents=ds_chunked['chunks'].tolist(),\n",
    "    metadatas=[{\"doc_id\": doc_id} for doc_id in ds_chunked['doc_id']],\n",
    "    ids=ds_chunked['chunk_id'].tolist()\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a quick look at an example question and the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[evaluation_data['question'][3]],\n",
    "    n_results=5)\n",
    "\n",
    "print(evaluation_data['question'][3])\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the query returns the ID's, scores (distances), metadata and documents (chunks) for the top 5 documents in the collection when scored by cosine similarity. The chunks will form our context, and we will use the metadata for lineage. In our case, we see that there are a number of chunks from the same document - this can be seen as a positive indicator given our corpus is quite specific and documents can be distinct. \n",
    "\n",
    "> NOTE: It will depend on your use case and data whether there is a concept of \"the right doc\"\n",
    "\n",
    "Now let's take a look at our augmentation and generation steps and apply this at scale!\n",
    "\n",
    "#### Augmentation and Generation\n",
    "\n",
    "Here we are enriching the question with the new (and hopefully relevant!) context we have unearthed from the vector database. To do that, we'll need another prompt template. Once we have this, we can submit the prompt to our generation model and receive the answer to our question.\n",
    "\n",
    "Let's use the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag.augmentation import get_context, contruct_prompt\n",
    "\n",
    "context = get_context(evaluation_data['question'][3], collection, 3)\n",
    "prompt = contruct_prompt(context, evaluation_data['question'][3])\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we've created a new prompt that's ready to be submited to our generation model. Let's take a look at a single call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper.openai_utils import general_prompt, create_client\n",
    "\n",
    "oai_client = create_client()\n",
    "\n",
    "response = general_prompt(oai_client, prompt, model=os.getenv(\"GEN_STEP_MODEL\"))\n",
    "\n",
    "print(f\"Question: {evaluation_data['question'][3]}\")\n",
    "print(f\"Correct Answer: {evaluation_data['ground_truth'][3]}\")\n",
    "\n",
    "print(f\"Generated Answer: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is looking pretty good! What you've likely just experienced is the infamous \"vibe check\" for LLM based applications. We'll get on to more formal measurement soon. But first, let's get answers to all 250 questions.\n",
    "\n",
    "> NOTE: The execution time of this will heavily depend on your model selection. For GPT-36-turbo-16k it should complete in roughly 3 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = os.getenv(\"GEN_STEP_MODEL\")\n",
    "multi_threading = True\n",
    "\n",
    "#Create a distinct copy of evaluation_data to store the results\n",
    "results_df = evaluation_data.copy()\n",
    "\n",
    "if os.path.exists(f'data/results-{experiment_name}-{model}.csv'):\n",
    "    print(\"File exists, reading in...\")\n",
    "\n",
    "    results_df = pd.read_csv(f'data/results-{experiment_name}-{model}.csv')\n",
    "\n",
    "else:\n",
    "    def generation_step(question):\n",
    "        context = get_context(question, collection,3)\n",
    "        prompt = contruct_prompt(context, question)\n",
    "        return general_prompt(oai_client, prompt, model=model)\n",
    "\n",
    "    if multi_threading == True:\n",
    "        with Pool() as pool:\n",
    "            results_multiprocessing = pool.map(generation_step, results_df['question'])\n",
    "        results_df['answer'] = results_multiprocessing\n",
    "\n",
    "    else:\n",
    "        results_df['answer'] = results_df['question'].apply(lambda x: generation_step(x))\n",
    "\n",
    "    #TODO: Refactor this so only one call for context\n",
    "\n",
    "    # Check if the column exists\n",
    "    if 'contexts' not in results_df.columns:\n",
    "        results_df['contexts'] = [get_context(q, collection) for q in results_df['question']]\n",
    "\n",
    "    #write out to CSV\n",
    "    results_df.to_csv(f'data/results-{experiment_name}-{model}.csv', index=False)\n",
    "\n",
    "display(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a dataframe with the questions, true answers, generated answers, and the context used to generate them, we can start to look at whether or not the answers are any good. To do that, we'll use a popular open source LLM evaluation framework called [Ragas](https://docs.ragas.io/en/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGE-2: RAG Evaluation Harness\n",
    "\n",
    "Now we've generated our answers, let's measure them. We'll be using the following measures to evaluate our results:\n",
    "\n",
    "1. *Faithfulness*: This measures the factual consistency of the generated answer against the given context. It is calculated from answer and retrieved context. The answer is scaled to (0,1) range. Higher the better.\n",
    "\n",
    "2. *Answer Relevancy*: The evaluation metric, Answer Relevancy, focuses on assessing how pertinent the generated answer is to the given prompt. A lower score is assigned to answers that are incomplete or contain redundant information and higher scores indicate better relevancy.\n",
    "\n",
    "3. *Answer Semantic Similarity*: The concept of Answer Semantic Similarity pertains to the assessment of the semantic resemblance between the generated answer and the ground truth. This evaluation is based on the ground truth and the answer, with values falling within the range of 0 to 1. A higher score signifies a better alignment between the generated answer and the ground truth.\n",
    "\n",
    "For more information on how these are calculated you can visit the documentation [here](https://docs.ragas.io/en/stable/concepts/metrics/index.html#ragas-metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.evaluate import ragas_evaluate\n",
    "\n",
    "\n",
    "#check if results_df exists, if not import it\n",
    "if 'results_df' not in locals():\n",
    "    import os\n",
    "    import ast\n",
    "    import pandas as pd\n",
    "    from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "    load_dotenv(find_dotenv())\n",
    "\n",
    "    experiment_name = \"baseline_pubmed_articles\"\n",
    "    model = os.getenv(\"GEN_STEP_MODEL\")\n",
    "    results_df = pd.read_csv(f'data/results-{experiment_name}-{model}.csv')\n",
    "\n",
    "    # Convert the contexts to a list of strings using ast\n",
    "    results_df['contexts'] = results_df['contexts'].apply(ast.literal_eval)\n",
    "\n",
    "# Calculate metrics and store\n",
    "results = ragas_evaluate(results_df)\n",
    "pd_results = results.to_pandas()\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(results)\n",
    "\n",
    "pd_results = results.to_pandas()\n",
    "display(pd_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
